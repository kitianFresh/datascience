{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# pandas 高级教程"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "# pass in column names for each CSV\n",
    "u_cols = ['user_id', 'age', 'sex', 'occupation', 'zip_code']\n",
    "users = pd.read_csv('ml-100k/u.user', sep='|', names=u_cols,\n",
    "                    encoding='latin-1')\n",
    "\n",
    "r_cols = ['user_id', 'movie_id', 'rating', 'unix_timestamp']\n",
    "ratings = pd.read_csv('ml-100k/u.data', sep='\\t', names=r_cols,\n",
    "                      encoding='latin-1')\n",
    "\n",
    "# the movies file contains columns indicating the movie's genres\n",
    "# let's only load the first five columns of the file with usecols\n",
    "m_cols = ['movie_id', 'title', 'release_date', 'video_release_date', 'imdb_url']\n",
    "movies = pd.read_csv('ml-100k/u.item', sep='|', names=m_cols, usecols=range(5),\n",
    "                     encoding='latin-1')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Inspection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1682 entries, 0 to 1681\n",
      "Data columns (total 5 columns):\n",
      "movie_id              1682 non-null int64\n",
      "title                 1682 non-null object\n",
      "release_date          1681 non-null object\n",
      "video_release_date    0 non-null float64\n",
      "imdb_url              1679 non-null object\n",
      "dtypes: float64(1), int64(1), object(3)\n",
      "memory usage: 65.8+ KB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "print(movies.info())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "movie_id                int64\n",
      "title                  object\n",
      "release_date           object\n",
      "video_release_date    float64\n",
      "imdb_url               object\n",
      "dtype: object\n"
     ]
    }
   ],
   "source": [
    "print(movies.dtypes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "描述方法会返回所有的 dtype 为数值类型的列的统计量"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "          user_id         age\n",
      "count  943.000000  943.000000\n",
      "mean   472.000000   34.051962\n",
      "std    272.364951   12.192740\n",
      "min      1.000000    7.000000\n",
      "25%    236.500000   25.000000\n",
      "50%    472.000000   31.000000\n",
      "75%    707.500000   43.000000\n",
      "max    943.000000   73.000000\n"
     ]
    }
   ],
   "source": [
    "print(users.describe())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    movie_id                          title release_date  video_release_date  \\\n",
      "20        21  Muppet Treasure Island (1996)  16-Feb-1996                 NaN   \n",
      "21        22              Braveheart (1995)  16-Feb-1996                 NaN   \n",
      "\n",
      "                                             imdb_url  \n",
      "20  http://us.imdb.com/M/title-exact?Muppet%20Trea...  \n",
      "21  http://us.imdb.com/M/title-exact?Braveheart%20...  \n"
     ]
    }
   ],
   "source": [
    "print(movies[20:22])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Boolean Indexing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   user_id  age sex occupation zip_code\n",
      "1        2   53   F      other    94043\n",
      "4        5   33   F      other    15213\n",
      "5        6   42   M  executive    98101\n",
      "\n",
      "\n",
      "     user_id  age sex  occupation zip_code\n",
      "18        19   40   M   librarian    02138\n",
      "82        83   40   M       other    44133\n",
      "115      116   40   M  healthcare    97232\n",
      "\n",
      "\n",
      "   user_id  age sex  occupation zip_code\n",
      "0        1   24   M  technician    85711\n",
      "1        2   53   F       other    94043\n",
      "2        3   23   M      writer    32067\n"
     ]
    }
   ],
   "source": [
    "# users older than 25\n",
    "print(users[users.age > 25].head(3))\n",
    "print('\\n')\n",
    "\n",
    "# users aged 40 AND male\n",
    "print(users[(users.age == 40) & (users.sex == 'M')].head(3))\n",
    "print('\\n')\n",
    "\n",
    "# users younger than 30 OR female\n",
    "print(users[(users.sex == 'F') | (users.age < 30)].head(3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 去除多余索引\n",
    "如果不带 inplace 参数，设置的索引不会改变原来的DataFrame，他返回一个新的！"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         age sex  occupation zip_code\n",
      "user_id                              \n",
      "1         24   M  technician    85711\n",
      "2         53   F       other    94043\n",
      "3         23   M      writer    32067\n",
      "4         24   M  technician    43537\n",
      "5         33   F       other    15213\n",
      "\n",
      "\n",
      "   user_id  age sex  occupation zip_code\n",
      "0        1   24   M  technician    85711\n",
      "1        2   53   F       other    94043\n",
      "2        3   23   M      writer    32067\n",
      "3        4   24   M  technician    43537\n",
      "4        5   33   F       other    15213\n",
      "\n",
      "^^^ I didn't actually change the DataFrame. ^^^\n",
      "\n",
      "         age sex  occupation zip_code\n",
      "user_id                              \n",
      "1         24   M  technician    85711\n",
      "2         53   F       other    94043\n",
      "3         23   M      writer    32067\n",
      "4         24   M  technician    43537\n",
      "5         33   F       other    15213\n",
      "\n",
      "^^^ set_index actually returns a new DataFrame. ^^^\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(users.set_index('user_id').head())\n",
    "print('\\n')\n",
    "\n",
    "print(users.head())\n",
    "print(\"\\n^^^ I didn't actually change the DataFrame. ^^^\\n\")\n",
    "\n",
    "with_new_index = users.set_index('user_id')\n",
    "print(with_new_index.head())\n",
    "print(\"\\n^^^ set_index actually returns a new DataFrame. ^^^\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "设置 inplace=True, 才可以改变原来的DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         age sex  occupation zip_code\n",
      "user_id                              \n",
      "1         24   M  technician    85711\n",
      "2         53   F       other    94043\n",
      "3         23   M      writer    32067\n",
      "4         24   M  technician    43537\n",
      "5         33   F       other    15213\n"
     ]
    }
   ],
   "source": [
    "users.set_index('user_id', inplace=True)\n",
    "print(users.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 按照索引定位\n",
    "注意这个索引是 DataFrame 的索引，不是我们定义的 index 索引"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "age                  36\n",
      "sex                   M\n",
      "occupation    executive\n",
      "zip_code          90254\n",
      "Name: 100, dtype: object\n",
      "\n",
      "\n",
      "         age sex occupation zip_code\n",
      "user_id                             \n",
      "2         53   F      other    94043\n",
      "51        28   M   educator    16509\n",
      "301       24   M    student    55439\n"
     ]
    }
   ],
   "source": [
    "print(users.iloc[99])\n",
    "print('\\n')\n",
    "print(users.iloc[[1, 50, 300]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 按照index/label 定位"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "age                  36\n",
      "sex                   M\n",
      "occupation    executive\n",
      "zip_code          90254\n",
      "Name: 100, dtype: object\n",
      "\n",
      "\n",
      "         age sex occupation zip_code\n",
      "user_id                             \n",
      "2         53   F      other    94043\n",
      "51        28   M   educator    16509\n",
      "301       24   M    student    55439\n"
     ]
    }
   ],
   "source": [
    "print(users.loc[100])\n",
    "# 当只有一行返回的时候，其实返回的是 Series\n",
    "print('\\n')\n",
    "print(users.loc[[2,51,301]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "再一次重置索引就可以恢复原来的样子"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   user_id  age sex  occupation zip_code\n",
      "0        1   24   M  technician    85711\n",
      "1        2   53   F       other    94043\n",
      "2        3   23   M      writer    32067\n",
      "3        4   24   M  technician    43537\n",
      "4        5   33   F       other    15213\n"
     ]
    }
   ],
   "source": [
    "users.reset_index(inplace=True)\n",
    "print(users.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# SQL-Like Join\n",
    "pandas.merge, 参数 how (on, left_on, right_on, left_index, right_index) 可以指定使用什么连接！默认是 innner join.\n",
    ">how : {'left', 'right', 'outer', 'inner'}, default 'inner'\n",
    "\n",
    "> - left: use only keys from left frame (SQL: left outer join)\n",
    "\n",
    "> - right: use only keys from right frame (SQL: right outer join)\n",
    "\n",
    "> - outer: use union of keys from both frames (SQL: full outer join)\n",
    "\n",
    "> - inner: use intersection of keys from both frames (SQL: inner join)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   key left_value\n",
      "0    0          a\n",
      "1    1          b\n",
      "2    2          c\n",
      "3    3          d\n",
      "4    4          e\n",
      "\n",
      "\n",
      "   key right_value\n",
      "0    2           f\n",
      "1    3           g\n",
      "2    4           h\n",
      "3    5           i\n",
      "4    6           j\n"
     ]
    }
   ],
   "source": [
    "left_frame = pd.DataFrame({'key': range(5), 'left_value': ['a', 'b', 'c', 'd', 'e']})\n",
    "right_frame = pd.DataFrame({'key': range(2,7), 'right_value': ['f', 'g','h', 'i', 'j']})\n",
    "print(left_frame)\n",
    "print('\\n')\n",
    "print(right_frame)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Inner Join(default)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   key left_value right_value\n",
      "0    2          c           f\n",
      "1    3          d           g\n",
      "2    4          e           h\n"
     ]
    }
   ],
   "source": [
    "print(pd.merge(left_frame, right_frame, on='key', how='inner'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "以上内部连接就相当与 SQL 语句：\n",
    "```sql\n",
    "SELECT left_frame.key, left_frame.left_value, right_frame.right_value\n",
    "FROM left_frame\n",
    "INNER JOIN right_frame\n",
    "    ON left_frame.key = right_frame.key;\n",
    "```\n",
    "当我们的左右两个表的主键列的列名不一样的时候，我们可以通过 参数 left_on 和 right_on 来指定 join 需要使用的主键列。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#pd.merge(left_frame, right_frame, left_on='left_key', right_on='right_key')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "当我们使用的是 表的索引 index 来做join， 那么可以使用 left_index 或者 right_index,还可以混合使用 index 和 column;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   key  key_x left_value  key_y right_value\n",
      "0    0      0          a      2           f\n",
      "1    1      1          b      3           g\n",
      "2    2      2          c      4           h\n",
      "3    3      3          d      5           i\n",
      "4    4      4          e      6           j\n"
     ]
    }
   ],
   "source": [
    "print(pd.merge(left_frame, right_frame, left_on='key', right_index=True))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Left Outer Join"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   key left_value right_value\n",
      "0    0          a         NaN\n",
      "1    1          b         NaN\n",
      "2    2          c           f\n",
      "3    3          d           g\n",
      "4    4          e           h\n"
     ]
    }
   ],
   "source": [
    "print(pd.merge(left_frame, right_frame, on='key', how='left'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "以上左外连接的SQL语句：\n",
    "```sql\n",
    "SELECT left_frame.key, left_frame.left_value, right_frame.right_value\n",
    "FROM left_frame\n",
    "LEFT JOIN right_frame\n",
    "    ON left_frame.key = right_frame.key;\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Right Outer Join"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   key left_value right_value\n",
      "0    2          c           f\n",
      "1    3          d           g\n",
      "2    4          e           h\n",
      "3    5        NaN           i\n",
      "4    6        NaN           j\n"
     ]
    }
   ],
   "source": [
    "print(pd.merge(left_frame, right_frame, on='key', how='right'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "以上右外连接的SQL语句：\n",
    "```sql\n",
    "SELECT right_frame.key, left_frame.left_value, right_frame.right_value\n",
    "FROM left_frame\n",
    "RIGHT JOIN right_frame\n",
    "    ON left_frame.key = right_frame.key;\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Full Outer Join"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   key left_value right_value\n",
      "0    0          a         NaN\n",
      "1    1          b         NaN\n",
      "2    2          c           f\n",
      "3    3          d           g\n",
      "4    4          e           h\n",
      "5    5        NaN           i\n",
      "6    6        NaN           j\n"
     ]
    }
   ],
   "source": [
    "print(pd.merge(left_frame, right_frame, on='key', how='outer'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "以上全外连接的SQL语句：\n",
    "```sql\n",
    "SELECT IFNULL(left_frame.key, right_frame.key) key, left_frame.left_value, right_frame.right_value\n",
    "FROM left_frame\n",
    "FULL OUTER JOIN right_frame\n",
    "    ON left_frame.key = right_frame.key;\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Combining\n",
    "我们可以使用 pandas.concat() 函数对 Series 和 DataFrame 进行组合连接操作。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   key left_value right_value\n",
      "0    0          a         NaN\n",
      "1    1          b         NaN\n",
      "2    2          c         NaN\n",
      "3    3          d         NaN\n",
      "4    4          e         NaN\n",
      "0    2        NaN           f\n",
      "1    3        NaN           g\n",
      "2    4        NaN           h\n",
      "3    5        NaN           i\n",
      "4    6        NaN           j\n"
     ]
    }
   ],
   "source": [
    "print(pd.concat([left_frame, right_frame]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "默认情况下，pd.concat() 会把具有相同 column name 的数据沿着 axis=0 的方向（即第一个维度）组合在一起，最终的结果就是行数增加了！\n",
    "\n",
    "我们也可以指定 axis=1 使其沿着第二维度做连接，那么他就会将相同 index 的列拼接在一起，最终的结果就是列数增加了！"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   key left_value  key right_value\n",
      "0    0          a    2           f\n",
      "1    1          b    3           g\n",
      "2    2          c    4           h\n",
      "3    3          d    5           i\n",
      "4    4          e    6           j\n"
     ]
    }
   ],
   "source": [
    "print(pd.concat([left_frame, right_frame], axis=1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Grouping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                    name                     title        department   salary\n",
      "0        AARON,  ELVIA J          WATER RATE TAKER       WATER MGMNT  85512.0\n",
      "1      AARON,  JEFFERY M            POLICE OFFICER            POLICE  75372.0\n",
      "2    AARON,  KIMBERLEI R  CHIEF CONTRACT EXPEDITER  GENERAL SERVICES  80916.0\n",
      "3    ABAD JR,  VICENTE M         CIVIL ENGINEER IV       WATER MGMNT  99648.0\n",
      "4  ABBATACOLA,  ROBERT J       ELECTRICAL MECHANIC          AVIATION  89440.0\n"
     ]
    }
   ],
   "source": [
    "headers = ['name', 'title', 'department', 'salary']\n",
    "chicago = pd.read_csv('./ml-100k/city-of-chicago-salaries.csv', \n",
    "                      header=0,\n",
    "                      names=headers,\n",
    "                      converters={'salary': lambda x: float(x.replace('$', ''))})\n",
    "print chicago.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<pandas.core.groupby.DataFrameGroupBy object at 0x7f497cc6d2d0>"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "by_dept = chicago.groupby('department')\n",
    "by_dept"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   name  title  salary\n",
      "department                            \n",
      "ADMIN HEARNG         42     42      42\n",
      "ANIMAL CONTRL        61     61      61\n",
      "AVIATION           1218   1218    1218\n",
      "BOARD OF ELECTION   110    110     110\n",
      "BOARD OF ETHICS       9      9       9\n",
      "\n",
      "\n",
      "department\n",
      "PUBLIC LIBRARY     926\n",
      "STREETS & SAN     2070\n",
      "TRANSPORTN        1168\n",
      "TREASURER           25\n",
      "WATER MGMNT       1857\n",
      "dtype: int64\n",
      "\n",
      "\n",
      "                       salary\n",
      "department                   \n",
      "HUMAN RESOURCES     4850928.0\n",
      "INSPECTOR GEN       4035150.0\n",
      "IPRA                7006128.0\n",
      "LAW                31883920.2\n",
      "LICENSE APPL COMM     65436.0\n",
      "\n",
      "\n",
      "                         salary\n",
      "department                     \n",
      "HUMAN RESOURCES    71337.176471\n",
      "INSPECTOR GEN      80703.000000\n",
      "IPRA               82425.035294\n",
      "LAW                70853.156000\n",
      "LICENSE APPL COMM  65436.000000\n",
      "\n",
      "\n",
      "                    salary\n",
      "department                \n",
      "HUMAN RESOURCES    68496.0\n",
      "INSPECTOR GEN      76116.0\n",
      "IPRA               82524.0\n",
      "LAW                66492.0\n",
      "LICENSE APPL COMM  65436.0\n"
     ]
    }
   ],
   "source": [
    "print(by_dept.count().head()) # NOT NULL records within each column\n",
    "print('\\n')\n",
    "print(by_dept.size().tail()) # total records for each department\n",
    "print('\\n')\n",
    "print(by_dept.sum()[20:25]) # total salaries of each department\n",
    "print('\\n')\n",
    "print(by_dept.mean()[20:25]) # average salary of each department\n",
    "print('\\n')\n",
    "print(by_dept.median()[20:25]) # take that, RDBMS!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "```sql\n",
    "SELECT department, COUNT(DISTINCT title)\n",
    "FROM chicago\n",
    "GROUP BY department\n",
    "ORDER BY 2 DESC\n",
    "LIMIT 5;\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "department\n",
       "WATER MGMNT    153\n",
       "TRANSPORTN     150\n",
       "POLICE         130\n",
       "AVIATION       125\n",
       "HEALTH         118\n",
       "Name: title, dtype: int64"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "by_dept.title.nunique().sort_values(ascending=False)[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                         name                            title  \\\n",
      "19175  MINIOTIS,  CONSTANTINE  SUPERINTENDENT'S CHIEF OF STAFF   \n",
      "3733     CALLAHAN,  MICHAEL E         DEPUTY FIRE COMMISSIONER   \n",
      "25981          SCOTT,  LOIS A          CHIEF FINANCIAL OFFICER   \n",
      "14098          JONES,  JOHN W                     PSYCHIATRIST   \n",
      "31996       ZONSIUS,  MICHAEL     MANAGING DEPUTY COMMISSIONER   \n",
      "17680    MARTINICO,  JOSEPH P           CHIEF LABOR NEGOTIATOR   \n",
      "29131       TULLY JR,  JOHN F     MANAGING DEPUTY COMMISSIONER   \n",
      "\n",
      "           department    salary  dept_rank  \n",
      "19175          POLICE  185004.0          3  \n",
      "3733             FIRE  178740.0          3  \n",
      "25981  MAYOR'S OFFICE  169992.0          3  \n",
      "14098          HEALTH  159668.6          3  \n",
      "31996        AVIATION  148644.0          3  \n",
      "17680             LAW  144036.0          3  \n",
      "29131   STREETS & SAN  142464.0          3  \n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "def ranker(df):\n",
    "    \"\"\"Assigns a rank to each employee based on salary, with 1 being the highest paid.\n",
    "    Assumes the data is DESC sorted.\"\"\"\n",
    "    df['dept_rank'] = np.arange(len(df)) + 1\n",
    "    return df\n",
    "chicago.sort_values('salary', ascending=False, inplace=True)\n",
    "chicago = chicago.groupby('department').apply(ranker)\n",
    "print(chicago[chicago.dept_rank == 3].head(7))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    user item  type date\n",
      "0      1    a     1    1\n",
      "8      2    d     3    1\n",
      "9      2    d     4    2\n",
      "2      1    a     4    3\n",
      "3      1    b     3    3\n",
      "10     2    f     5    3\n",
      "11     2    f     6    3\n",
      "4      1    b     5    4\n",
      "5      1    c     6    4\n",
      "12     3    c     4    4\n",
      "13     3    c     2    4\n",
      "6      2    b     1    5\n",
      "14     3    e     3    5\n",
      "          item date\n",
      "user type          \n",
      "1    1       a    1\n",
      "2    3       d    1\n",
      "     4       d    2\n",
      "1    4       a    3\n",
      "     3       b    3\n",
      "2    5       f    3\n",
      "     6       f    3\n",
      "1    5       b    4\n",
      "     6       c    4\n",
      "3    4       c    4\n",
      "     2       c    4\n",
      "2    1       b    5\n",
      "3    3       e    5\n",
      "    user item  type date\n",
      "0      1    a     1    1\n",
      "1      1    a     1    2\n",
      "2      1    a     4    3\n",
      "3      1    b     3    3\n",
      "4      1    b     5    4\n",
      "5      1    c     6    4\n",
      "6      2    b     1    5\n",
      "7      2    b     1    6\n",
      "8      2    d     3    1\n",
      "9      2    d     4    2\n",
      "10     2    f     5    3\n",
      "11     2    f     6    3\n",
      "12     3    c     4    4\n",
      "13     3    c     2    4\n",
      "14     3    e     3    5\n",
      "15     3    e     3    6\n"
     ]
    }
   ],
   "source": [
    "user_action = pd.DataFrame({\"user\": [1,1,1,1,1,1,2,2,2,2,2,2,3,3,3,3],\n",
    "                            \"item\": ['a', 'a', 'a', 'b', 'b', 'c', 'b', 'b', 'd', 'd', 'f', 'f', 'c','c', 'e', 'e'],\n",
    "                     \"type\": [1, 1, 4, 3, 5, 6, 1, 1, 3, 4, 5, 6, 4, 2, 3, 3],\n",
    "                     \"date\": ['1', '2', '3', '3', '4', '4', '5', '6','1', '2', '3', '3', '4', '4', '5', '6']},\n",
    "                     columns=['user','item','type', 'date'])\n",
    "\n",
    "result = user_action.sort_values(['date'],axis=0).drop_duplicates(subset=['user', 'type'],keep='first')\n",
    "print result\n",
    "result.set_index(['user','type'], inplace=True)\n",
    "print result\n",
    "print user_action"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    user item  browse_num  addcart_num  delcart_num  buy_num  favor_num  \\\n",
      "0      1    a           2            0            0        1          0   \n",
      "1      1    a           2            0            0        1          0   \n",
      "2      1    a           2            0            0        1          0   \n",
      "3      1    b           0            0            1        0          1   \n",
      "4      1    b           0            0            1        0          1   \n",
      "5      1    c           0            0            0        0          0   \n",
      "6      2    b           2            0            0        0          0   \n",
      "7      2    b           2            0            0        0          0   \n",
      "8      2    d           0            0            1        1          0   \n",
      "9      2    d           0            0            1        1          0   \n",
      "10     2    f           0            0            0        0          1   \n",
      "11     2    f           0            0            0        0          1   \n",
      "12     3    c           0            1            0        1          0   \n",
      "13     3    c           0            1            0        1          0   \n",
      "14     3    e           0            0            2        0          0   \n",
      "15     3    e           0            0            2        0          0   \n",
      "\n",
      "    click_num  \n",
      "0           0  \n",
      "1           0  \n",
      "2           0  \n",
      "3           0  \n",
      "4           0  \n",
      "5           1  \n",
      "6           0  \n",
      "7           0  \n",
      "8           0  \n",
      "9           0  \n",
      "10          1  \n",
      "11          1  \n",
      "12          0  \n",
      "13          0  \n",
      "14          0  \n",
      "15          0  \n"
     ]
    }
   ],
   "source": [
    "from collections import Counter\n",
    "def add_type_count(group):\n",
    "    user_behaviors = group.type.astype(int)\n",
    "    type_cnt = Counter(user_behaviors)\n",
    "    # 1: 浏览 2: 加购 3: 删除\n",
    "    # 4: 购买 5: 收藏 6: 点击\n",
    "    group['browse_num'] = type_cnt[1]\n",
    "    group['addcart_num'] = type_cnt[2]\n",
    "    group['delcart_num'] = type_cnt[3]\n",
    "    group['buy_num'] = type_cnt[4]\n",
    "    group['favor_num'] = type_cnt[5]\n",
    "    group['click_num'] = type_cnt[6]\n",
    "\n",
    "    return group[['user', 'item', 'browse_num', 'addcart_num',\n",
    "                  'delcart_num', 'buy_num', 'favor_num',\n",
    "                  'click_num']]\n",
    "\n",
    "# df_ac = user_action.groupby(['user', 'item'], as_index=True).apply(add_type_count)\n",
    "# print df_ac\n",
    "# print('\\n')\n",
    "df_ac = user_action.groupby(['user', 'item'], as_index=False).apply(add_type_count)\n",
    "print df_ac"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    user item  browse_num  addcart_num  delcart_num  buy_num  favor_num  \\\n",
      "0      1    a           2            0            0        1          0   \n",
      "3      1    b           0            0            1        0          1   \n",
      "5      1    c           0            0            0        0          0   \n",
      "6      2    b           2            0            0        0          0   \n",
      "8      2    d           0            0            1        1          0   \n",
      "10     2    f           0            0            0        0          1   \n",
      "12     3    c           0            1            0        1          0   \n",
      "14     3    e           0            0            2        0          0   \n",
      "\n",
      "    click_num  \n",
      "0           0  \n",
      "3           0  \n",
      "5           1  \n",
      "6           0  \n",
      "8           0  \n",
      "10          1  \n",
      "12          0  \n",
      "14          0  \n"
     ]
    }
   ],
   "source": [
    "df_ac = user_action.groupby(['user', 'item'], as_index=False).apply(add_type_count).drop_duplicates(subset=['user', 'item'])\n",
    "print df_ac"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
